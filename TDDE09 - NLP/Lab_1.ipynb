{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "**Due date:** 2017-01-27\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Students:** Johan Lindström (johli160), Jonathan Sjölund (jonsj507)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab you will implement and compare the performance of two simple text classifiers: a Naive Bayes classifier and a classifier based on the averaged perceptron.\n",
    "\n",
    "The data set that you will use in this lab is the [review polarity data set](https://www.cs.cornell.edu/people/pabo/movie-review-data/) first used by [Pang and Lee (2004)](http://www.aclweb.org/anthology/P04-1035). This data set consists of 2,000 movie reviews, each of which has been tagged as either positive or negative towards the movie at hand. The data is originally distributed as a collection of text files. For this lab we have put all files into two JSON files, one for training and one for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing the module for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nlp1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell loads the training data and the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data = nlp1.load_data(\"/home/TDDE09/labs/nlp1/review_polarity.train.json\")\n",
    "test_data = nlp1.load_data(\"/home/TDDE09/labs/nlp1/review_polarity.test.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you will see, each data instance is a pair whose first component is a document, represented as a list of tokens, and whose second component is the gold-standard polarity of the review&nbsp;&ndash; either positive (`pos`) or negative (`neg`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['this', 'film', 'is', 'extraordinarily', 'horrendous', 'and', \"i'm\", 'not', 'going', 'to', 'waste', 'any', 'more', 'words', 'on', 'it', '.'], 'neg')\n"
     ]
    }
   ],
   "source": [
    "print(training_data[813])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two classifiers that you will implement in this lab should inherit from the following class, whose only method `predict` takes a document and returns the predicted class for that document (here: the polarity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Classifier(object):\n",
    "\n",
    "    def predict(self, d):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing that you will have do is to implement a function\n",
    "\n",
    "`accuracy(classifier, data)`\n",
    "\n",
    "that computes the accuracy of a classifier on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def accuracy(classifier, data):\n",
    "    # TODO: Replace the following line with your own code to solve Problem 1\n",
    "    correct = 0\n",
    "    for x in range(0, len(data)):\n",
    "        if(classifier.predict(data[x][0]) == data[x][1]):\n",
    "            correct += 1\n",
    "    return(correct/len(data))\n",
    "    #return nlp1.accuracy(classifier, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can test this function by computing the accuracy of a Naive Bayes classifier on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.765\n"
     ]
    }
   ],
   "source": [
    "classifier = nlp1.NaiveBayesClassifier.train(training_data)\n",
    "print(accuracy(classifier, test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"panel panel-primary\">\n",
    "<div class=\"panel-heading\">Problem 1</div>\n",
    "<div class=\"panel-body\">\n",
    "Provide your own implementation of the `accuracy()` function. Test your implementation by redoing the evaluation. You should get exactly the same results as before.\n",
    "</div>\n",
    "</div>\n",
    "\n",
    "**Hint:** Using an appropriate function from the `statistics` module, this problem can be solved in a one-liner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement the Naive Bayes classifier, you should complete the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MyNaiveBayesClassifier(Classifier):\n",
    "\n",
    "    def predict(self, d):\n",
    "        # TODO: Replace the following line with your own code to solve Problem 2\n",
    "        import math\n",
    "        negScore = math.log(probNeg,10)\n",
    "        posScore = math.log(probPos,10)\n",
    "        \n",
    "        for x in range(0,len(d)):\n",
    "            \n",
    "            if(d[x] in dictNeg):\n",
    "                negScore = negScore+math.log(dictNeg[d[x]]/fwcNeg,10)\n",
    "            else:\n",
    "                negScore = negScore+math.log(1/fwcNeg,10)\n",
    "                   \n",
    "            if(d[x] in dictPos):\n",
    "                posScore = posScore+math.log(dictPos[d[x]]/fwcPos,10)\n",
    "            else:\n",
    "                posScore = posScore+math.log(1/fwcPos,10)\n",
    "\n",
    "            \n",
    "        if(negScore > posScore):\n",
    "            return 'neg'\n",
    "        else:\n",
    "            return 'pos'\n",
    "\n",
    "    \n",
    "    @classmethod\n",
    "    def train(cls, data, k=1):\n",
    "        # TODO: Replace the following line with your own code to solve Problem 2\n",
    "        numOfNeg = 0\n",
    "        listOfNegWord = []\n",
    "        listOfPosWord = []\n",
    "        \n",
    "        global dictNeg, dictPos, probNeg, probPos,fwcNeg,fwcPos\n",
    "        dictNeg = {}\n",
    "        dictPos = {}\n",
    "        \n",
    "        for x in range(0,len(data)):\n",
    "            currList = data[x][0]\n",
    "            if(data[x][1] == 'neg'):\n",
    "                numOfNeg += 1\n",
    "                listOfNegWord = listOfNegWord + currList\n",
    "                for y in range(0,len(currList)):\n",
    "                    if(currList[y] in dictNeg):\n",
    "                        dictNeg.update({currList[y]:dictNeg[currList[y]]+1})\n",
    "                    else:\n",
    "                        dictNeg.update({currList[y]:1+k})\n",
    "                                       \n",
    "            else:\n",
    "                listOfPosWord = listOfPosWord + currList\n",
    "                for y in range(0,len(currList)):\n",
    "                    if(currList[y] in dictPos):\n",
    "                        dictPos.update({currList[y]:dictPos[currList[y]]+1})\n",
    "                    else:\n",
    "                        dictPos.update({currList[y]:1+k})\n",
    "             \n",
    "        probNeg = numOfNeg/len(data)   #P(c)\n",
    "        probPos = 1-probNeg  \n",
    "        \n",
    "        listOfAllWords = listOfNegWord+listOfPosWord\n",
    "        uniqueAllWords = set(listOfAllWords)\n",
    "        uniqueAllWords = list(uniqueAllWords)\n",
    "        numOfUniqAllWords = len(uniqueAllWords)\n",
    "        \n",
    "        numOfNegWord = len(listOfNegWord)\n",
    "        fwcNeg =  numOfNegWord+k*numOfUniqAllWords  # frequency of all words amongst all negative documents\n",
    "        \n",
    "        numOfPosWord = len(listOfPosWord)\n",
    "        fwcPos =  numOfPosWord+k*numOfUniqAllWords  # frequency of all words amongst all negative documents\n",
    "    \n",
    "        return cls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this skeleton the method `predict()` should implement the Naive Bayes classification rule. The method `train()` should return a new classifier that has been trained on the specified training data using maximum likelihood estimation with add-$k$ smoothing.\n",
    "\n",
    "To test your implementation, you can re-do the evaluation from above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.765\n"
     ]
    }
   ],
   "source": [
    "classifier1 = MyNaiveBayesClassifier.train(training_data)\n",
    "print(accuracy(classifier1, test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"panel panel-primary\">\n",
    "<div class=\"panel-heading\">Problem 2</div>\n",
    "<div class=\"panel-body\">\n",
    "Implement the two methods in `MyNaiveBayesClassifier`. Test your implementation by evaluating on the test data. Your results should be very similar to the ones that you got when you evaluated your accuracy function in Problem&nbsp;1.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Averaged perceptron classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the code skeleton for the averaged perceptron classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MyPerceptronClassifier(Classifier):\n",
    "\n",
    "    def predict(self, x):\n",
    "        # TODO: Replace the following line with your own code to solve Problem 3\n",
    "        xDict = {}\n",
    "        for i in range(0,len(x)):\n",
    "            if(x[i] in xDict):\n",
    "                xDict.update({x[i]:xDict[x[i]]+1})\n",
    "            else:\n",
    "                xDict.update({x[i]:1})\n",
    "        \n",
    "        pNeg = 0\n",
    "        pPos = 0\n",
    "                \n",
    "        for word in xDict:\n",
    "            if(word in self.weights['neg']):\n",
    "                 pNeg = pNeg + self.weights['neg'][word]\n",
    "            if(word in self.weights['pos']):   \n",
    "                 pPos = pPos + self.weights['pos'][word]\n",
    "                \n",
    "            if(pNeg >= pPos):\n",
    "                 p = 'neg'\n",
    "            else:\n",
    "                p = 'pos'\n",
    "         \n",
    "        return p\n",
    "        \n",
    "\n",
    "    @classmethod\n",
    "    def train(cls, data, n_epochs=1):\n",
    "        # TODO: Replace the following line with your own code to solve Problem 3\n",
    "        perc = cls()\n",
    "        dictNeg = {}\n",
    "        dictPos = {}\n",
    "        perc.classes = ['pos', 'neg']\n",
    "        \n",
    "        ######## Only used to get every word that are in the negative and positive review #########\n",
    "        for x in range(0,len(data)):\n",
    "            currList = data[x][0]\n",
    "            if(data[x][1] == 'neg'):\n",
    "                for y in range(0,len(currList)):\n",
    "                    if(currList[y] in dictNeg):\n",
    "                        dictNeg.update({currList[y]:dictNeg[currList[y]]+1})\n",
    "                    else:\n",
    "                        dictNeg.update({currList[y]:1})\n",
    "                                       \n",
    "            else:\n",
    "                for y in range(0,len(currList)):\n",
    "                    if(currList[y] in dictPos):\n",
    "                        dictPos.update({currList[y]:dictPos[currList[y]]+1})\n",
    "                    else:\n",
    "                        dictPos.update({currList[y]:1})\n",
    "        \n",
    "        ###########################################################################################\n",
    "        \n",
    "        tempPos = dictPos\n",
    "        tempNeg = dictNeg\n",
    "        for k in dictPos:\n",
    "            tempPos[k] = 0\n",
    "        for k in dictNeg:\n",
    "            tempNeg[k] = 0\n",
    "            \n",
    "        perc.weights = {'pos' : {}, 'neg' : {}} #Two different dictionaries for each class\n",
    "        perc.weights.update({'pos':tempPos})\n",
    "        perc.weights.update({'neg':tempNeg})\n",
    "        \n",
    "        acc = {'pos':{}, 'neg':{}} #dictionary of dictionaries\n",
    "        acc.update({'pos':tempPos})\n",
    "        acc.update({'neg':tempNeg})\n",
    "        \n",
    "        count = 1\n",
    "        for e in range(n_epochs):\n",
    "            for x,y in data:\n",
    "                #x is a document, should be transformed from a list to a dictionary\n",
    "                #y is a binary value for the gold standard class for the document\n",
    "                xDict = {}\n",
    "                for i in range(0,len(x)):\n",
    "                    if(x[i] in xDict):\n",
    "                        xDict.update({x[i]:xDict[x[i]]+1})\n",
    "                    else:\n",
    "                        xDict.update({x[i]:1})\n",
    "        \n",
    "                pNeg = 0\n",
    "                pPos = 0\n",
    "                \n",
    "                p = perc.predict(x) # Predict the class\n",
    "                \n",
    "                if(p != y):\n",
    "                    for word in xDict:  #for-loops with dictionary\n",
    "                        if(word in perc.weights[p]):\n",
    "                            perc.weights[p][word] -= 1\n",
    "                            acc[p][word] -= count\n",
    "                        if(word in perc.weights[y]):       \n",
    "                            perc.weights[y][word] += 1\n",
    "                            acc[y][word] += count\n",
    "                count += 1 \n",
    "        for k in perc.classes:\n",
    "            for word in xDict:  #for-loops with dictionary\n",
    "                if(word in perc.weights[k]):\n",
    "                    z=1 # ignore this\n",
    "                    perc.weights[k][word] = perc.weights[k][word] - acc[k][word]/count #averaging\n",
    "        return perc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this skeleton, the method `predict()` should implement the perceptron classification rule. The method `train()` should return a new classifier that has been trained on the specified training data using averaged perceptron training for the specified number of epochs.\n",
    "\n",
    "To test your implementation, as before you can train a classifier on the training data and evaluate it on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.785\n"
     ]
    }
   ],
   "source": [
    "classifier2 = MyPerceptronClassifier.train(training_data)\n",
    "print(accuracy(classifier2, test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"panel panel-primary\">\n",
    "<div class=\"panel-heading\">Problem 3</div>\n",
    "<div class=\"panel-body\">\n",
    "Implement the two methods in `MyPerceptronClassifier`. Test your implementation by evaluating on the test data. You should get results in the 70&ndash;80% range. What happens if you repeat the experiment but do not do averaging? What happens when you train the classifier for two epochs? Enter your results into the table below.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr><td></td><td>averaging</td><td>no averaging</td></tr>\n",
    "<tr><td>1 epoch</td><td>0.785</td><td>0.785</td></tr>\n",
    "<tr><td>2 epochs</td><td>0.82</td><td>0.82</td></tr>\n",
    "</table>\n",
    "\n",
    "The reason we may get the same result for averaging and no averaging may be because the problem at hand is not linearly separable and since averaging is limited to only those problems the averaging here may or may not help at all. Which is the case here where there is no difference between using and not using averaging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Switching to binary features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lab so far, a document is represented as a list of the words that occur in it. For sentiment classification, several authors have suggested that a *binary* document representation, where each word is represented only once, can produce better results. In the last problem you will try to confirm this finding.\n",
    "\n",
    "Your task is to implement a function `binarize()` that converts data into the binary representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def binarize(data):\n",
    "    # TODO: Replace the following line to solve Problem 4\n",
    "    temp = {}\n",
    "\n",
    "    for i in range(0,len(data)):\n",
    "        temp = data[i][0]\n",
    "        temp = set(temp)\n",
    "        temp = list(temp)\n",
    "        data[i] = (temp,data[i][1])\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function is to be used in the following context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.805\n",
      "0.785\n"
     ]
    }
   ],
   "source": [
    "binarized_training_data = binarize(training_data)\n",
    "binarized_test_data = binarize(test_data)\n",
    "\n",
    "classifier3 = MyNaiveBayesClassifier.train(binarized_training_data)\n",
    "print(accuracy(classifier3, binarized_test_data))\n",
    "\n",
    "classifier4 = MyPerceptronClassifier.train(binarized_training_data)\n",
    "print(accuracy(classifier4, binarized_test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"panel panel-primary\">\n",
    "<div class=\"panel-heading\">Problem 4</div>\n",
    "<div class=\"panel-body\">\n",
    "Implement the `binarize()` function and run the evaluation. What do you observe? Summarise your results in one or two sentences.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes is better because it is more reasonable to look at the frequency of words over documents instead of frequency per document since frequency of stop words increases alot for bigger documents and are not relevant at all when classifying, with binarization we minimize this thus giving a more fair score. \n",
    "For the averaging perceptron classifier the result does not change with or without averaging which is logical in a sense since we do not look at frequency of words because we use dictionary, only occurrences, which means that we already look at binary values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
