{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "**Due date:** 2017-02-10\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: Part-of-Speech Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Students:** Johan Lindström (johli160), Jonathan Sjölund (jonsj507)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part-of-speech (POS) tagging is the task of labelling words (tokens) with parts of speech such as noun, adjective, and verb. In this lab you will implement a POS tagger based on the averaged perceptron and evaluate it on the [Stockholm Umeå Corpus (SUC)](http://spraakbanken.gu.se/eng/resources/suc), a Swedish corpus containing more than 74,000 sentences (1.1&nbsp;million tokens), which were manually annotated with, among others, parts of speech. The corpus is divided into two files:\n",
    "\n",
    "<table align=\"left\">\n",
    "<tr><td><code>suc-train.txt</code></td><td style=\"text-align: right\">72,594 sentences</td><td style=\"text-align: right\">1,142,802 tokens</td></tr>\n",
    "<tr><td><code>suc-test.txt</code></td><td style=\"text-align: right\">1,569 sentences</td><td style=\"text-align: right\">23,319 tokens</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing the Python module that is required for this lab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nlp3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell loads the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data = nlp3.read_data(\"/home/TDDE09/labs/nlp3/suc-train.txt\")\n",
    "test_data = nlp3.read_data(\"/home/TDDE09/labs/nlp3/suc-test.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both data sets consist of tagged sentences. In Python, a tagged sentence is represented as a list of string pairs, where the first component of each pair represents a word and the second component represents a part-of-speech tag. Run the following code cell to see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Och', 'KN'),\n",
       " ('det', 'PN'),\n",
       " ('är', 'VB'),\n",
       " ('som', 'KN'),\n",
       " ('segerherre', 'NN'),\n",
       " ('han', 'PN'),\n",
       " ('vill', 'VB'),\n",
       " ('göra', 'VB'),\n",
       " ('politik', 'NN'),\n",
       " ('.', 'MAD')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[42]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell extracts all unique tags from the training data. The tags are explained and exemplified in Table&nbsp;12 (page&nbsp;20) of the [SUC 2.0 Manual](https://spraakbanken.gu.se/parole/Docs/SUC2.0-manual.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB DT HA HD HP HS IE IN JJ KN MAD MID NN PAD PC PL PM PN PP PS RG RO SN UO VB\n"
     ]
    }
   ],
   "source": [
    "suc_tags = set()\n",
    "for tagged_sentence in training_data:\n",
    "    for word, tag in tagged_sentence:\n",
    "        suc_tags.add(tag)\n",
    "suc_tags = sorted(suc_tags)\n",
    "print(\" \".join(suc_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next code cell to train the default tagger, tag the sample sentence from above, and evaluate the tagger on the test data. Note that for reasons of speed, this only uses the first 1,000 sentences of the training data; for higher accuracies you should train on the complete training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 99.90%\n",
      "[('Och', 'KN'), ('det', 'PN'), ('är', 'VB'), ('som', 'HP'), ('segerherre', 'VB'), ('han', 'PN'), ('vill', 'VB'), ('göra', 'VB'), ('politik', 'NN'), ('.', 'MAD')]\n",
      "Accuracy: 75.96%\n"
     ]
    }
   ],
   "source": [
    "tagger = nlp3.PerceptronTagger(suc_tags)\n",
    "tagger.train(training_data[:1000])\n",
    "print(tagger.tag([word for word, tag in training_data[42]]))\n",
    "matrix = nlp3.confusion_matrix(tagger, test_data)\n",
    "print(\"Accuracy: {:.2%}\".format(nlp3.accuracy(matrix)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your main task in this lab is to re-implement the two central methods of the default tagger:\n",
    "\n",
    "* `train()`, which takes a list of tagged sentences and trains the tagger using the averaged perceptron learning algorithm\n",
    "\n",
    "* `tag()`, which takes a list of words (strings) and returns a tagged sentence\n",
    "\n",
    "You are of course free to add other methods to your class if you deem it appropriate to do so.\n",
    "\n",
    "In implementing the tagger you will be able to reuse code from your implementation of the averaged perceptron classifier in lab&nbsp;1. However, for this lab it is crucial that you can handle multiple classes, as the tagger needs one class per POS tag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"panel panel-primary\">\n",
    "<div class=\"panel-heading\">Problem 1</div>\n",
    "<div class=\"panel-body\">\n",
    "Implement a part-of-speech tagger based on the averaged perceptron, train it on the training data, and evaluate performance on the test data. Your tagger should get the same results as the default tagger.\n",
    "</div>\n",
    "</div>\n",
    "\n",
    "Starter code for this problem is given in the following code cell. The provided class simply inherits from `nlp3.PerceptronTagger` and calls the methods in the superclass. Your task is to replace these calls with your own code. You will note that there is a third method `get_features()`; you do not need to touch this method unless you want to do the advanced part of this lab (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class OurTagger(nlp3.PerceptronTagger):\n",
    "    \n",
    "    \n",
    "    # Added code\n",
    "    def predict(self,x):\n",
    "        #import random\n",
    "        scores = {}\n",
    "        for tag_class in self.classes:      \n",
    "            scores.update({tag_class:0}) #Create a dict with all the tags      \n",
    "        for tag in self.classes:\n",
    "            for f in x:\n",
    "                if(f in self.weights[tag]):\n",
    "                    scores.update({tag:scores[tag]+self.weights[tag][f]})\n",
    "                else:\n",
    "                    self.weights[tag].update({f:0})\n",
    "                    self.acc[tag].update({f:0})\n",
    "                    scores.update({tag:scores[tag]+self.weights[tag][f]})\n",
    "        \n",
    "        #Tittar om alla har lika mycket score, om de har de så väljer vi någon specific annars så tar den med störst score\n",
    "        if(scores[max(scores, key=lambda tag: scores[tag])] >0): \n",
    "            return max(scores, key=lambda tag: scores[tag])\n",
    "        else:\n",
    "            #print(random.choice(self.classes))\n",
    "            #return random.choice(self.classes) \n",
    "            return self.classes[9] #Tag 9, störst hittills med 76.31 %\n",
    "        \n",
    "\n",
    "    def __init__(self, tags):\n",
    "        \"\"\"Creates a new tagger that uses the specified tag set.\"\"\"\n",
    "        super().__init__(tags)\n",
    "        self.tags = tags\n",
    "\n",
    "    def tag(self, words):\n",
    "        \"\"\"Tags the specified words, returning a tagged sentence.\"\"\"\n",
    "        pred_tags = []\n",
    "        tagged_words = []\n",
    "        for i in range(0,len(words)):\n",
    "            f = self.get_features(words,i,pred_tags) #Hämtar features för den hämtade token+tagg\n",
    "            p = self.predict(f) #Predicera tagg mha. features\n",
    "            pred_tags.append(p)\n",
    "            temp = (words[i],p)\n",
    "            tagged_words.append(temp)\n",
    "        \n",
    "        return tagged_words \n",
    "    \n",
    "        #TODO: Replace the following line with your own code\n",
    "        #return super().tag(words)\n",
    "    \n",
    "    def train(self, tagged_sentences, report_progress=True):\n",
    "        \"\"\"Trains this tagger on the specified gold-standard data.\"\"\"\n",
    "        suc_tags = set()\n",
    "        for tagged_sentence in training_data:\n",
    "            for word, tag in tagged_sentence:\n",
    "                suc_tags.add(tag)\n",
    "        self.classes = sorted(suc_tags) #Skapar en lista med varje klass\n",
    "        \n",
    "        self.weights = {}\n",
    "        self.acc = {}\n",
    "        for tag_class in suc_tags: #Går igenom varje möjlig tagg och skapar en dict av dict för den    \n",
    "            self.weights.update({tag_class:{}})\n",
    "            self.acc.update({tag_class:{}})    \n",
    "            \n",
    "        count = 1\n",
    "        for x in tagged_sentences: #En mening där varje ord har en tagg\n",
    "            tokens = []\n",
    "            tags = []\n",
    "            for tag_token in x: #Går igenom meningen och tar ut tokenet och taggen för sig och lägger i varsin lista\n",
    "                tokens.append(tag_token[0])\n",
    "                tags.append(tag_token[1])\n",
    "            \n",
    "            pred_tags = []    \n",
    "            for i in range(0,len(x)): #Går igenom varje mening och hämtar token+tagg\n",
    "                f = self.get_features(tokens,i,pred_tags) #Hämtar features för den hämtade token+tagg\n",
    "                p = self.predict(f) #Predicera tagg mha. features\n",
    "                pred_tags.append(p)\n",
    "                y = tags[i] #Den korrekta taggen för token\n",
    "                \n",
    "                if(p != y):\n",
    "                    for feature in f:#Går igenom varje feature om predict inte matcher med rätt tagg\n",
    "                        if(feature in self.weights[p]): \n",
    "                            self.weights[p][feature] -= 1 #Minskar weighten för features i fel tagg\n",
    "                            self.acc[p][feature] -= count\n",
    "                            \n",
    "                        if(feature in self.weights[y]):\n",
    "                            self.weights[y][feature] += 1 #Ökar weighten för features soma ska vara i rätt tagg\n",
    "                            self.acc[y][feature] += count\n",
    "            count += 1\n",
    "        for k in suc_tags:\n",
    "            for word in self.weights[k]:\n",
    "                self.weights[k][word] = self.weights[k][word] - self.acc[k][word]/count #Averaging\n",
    "                \n",
    "        # TODO: Replace the following line with your own code\n",
    "        #super().train(tagged_sentences, report_progress)\n",
    "\n",
    "    def get_features(self, tokens, i, pred_tags):\n",
    "        \"\"\"Extracts the feature list for the specified configuration.\"\"\"\n",
    "        # TODO: For the advanced part, replace the following line with your own code\n",
    "        features = list();\n",
    "     \n",
    "                \n",
    "        x = len(pred_tags)\n",
    "        \n",
    "        features.append(tokens[i])\n",
    "        features.append(tokens[i])\n",
    "        features.append(tokens[i])\n",
    "        features.append(tokens[i])\n",
    "\n",
    "        \n",
    "        if(x > 0):\n",
    "            features.append(pred_tags[i-1])\n",
    "            features.append(tokens[i-1])\n",
    "            features.append((pred_tags[i-1],tokens[i-1]))\n",
    "            features.append((tokens[i-1],tokens[i]))\n",
    "        else:\n",
    "            features.append(\"BOSTAG\")\n",
    "            features.append(\"BOS\")\n",
    "            features.append((\"BOSTAG\",\"BOS\"))\n",
    "            features.append((\"BOS\",tokens[i]))\n",
    "\n",
    "                \n",
    "        \n",
    "        if(i == len(tokens)-1):\n",
    "            features.append((\"EOS\",tokens[i]))\n",
    "        else:\n",
    "            features.append((tokens[i+1],tokens[i]))\n",
    "        \n",
    "        return features; \n",
    "        \n",
    "        #return super().get_features(tokens, i, pred_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to test your tagger. At the end of the lab you should get the same results as in the evaluation of the default tagger (assuming that you do not change the feature extraction, see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Och', 'KN'), ('det', 'PN'), ('är', 'VB'), ('som', 'KN'), ('segerherre', 'NN'), ('han', 'PN'), ('vill', 'VB'), ('göra', 'VB'), ('politik', 'NN'), ('.', 'MAD')]\n",
      "Accuracy: 93.12%\n"
     ]
    }
   ],
   "source": [
    "our_tagger = OurTagger(suc_tags)\n",
    "our_tagger.train(training_data[:])\n",
    "print(our_tagger.tag([word for word, tag in training_data[42]]))\n",
    "our_matrix = nlp3.confusion_matrix(our_tagger, test_data)\n",
    "print(\"Accuracy: {:.2%}\".format(nlp3.accuracy(our_matrix)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what follows, we try to give you an idea of what the two methods `train()` and `tag()` do. We start with the latter.\n",
    "\n",
    "### Tagging\n",
    "\n",
    "The default tagger implements the sequence model presented in the lecture. In this model, sentences are tagged from left to right. A **configuration** consists of the list of words, the index of the current word, and the list of already predicted tags. For each word in the sentence, the tagger calls the method `get_features()` to obtain a feature vector for the current configuration. To illustrate how this works, we define a variant of the default tagger that only extracts a single feature, the current word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DemoTagger(nlp3.PerceptronTagger):\n",
    "    \n",
    "    def get_features(self, words, i, pred_tags):\n",
    "        if self.debug:\n",
    "            print(\"words: {}\".format(\" \".join(words)))\n",
    "            print(\"i: {} (current word: {})\".format(i, words[i]))\n",
    "            print(\"pred_tags: {}\".format(\" \".join(pred_tags)))\n",
    "            print()\n",
    "        return [words[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train this tagger and evaluate it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 99.90%\n",
      "Accuracy: 69.18%\n"
     ]
    }
   ],
   "source": [
    "demo_tagger = DemoTagger(suc_tags)\n",
    "demo_tagger.debug = False\n",
    "demo_tagger.train(training_data[:1000])\n",
    "demo_matrix = nlp3.confusion_matrix(demo_tagger, test_data)\n",
    "print(\"Accuracy: {:.2%}\".format(nlp3.accuracy(demo_matrix)))\n",
    "demo_tagger.debug = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the features that are extracted when the system tags the sentence *Anna älskar Kurt*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words: Anna älskar Kurt\n",
      "i: 0 (current word: Anna)\n",
      "pred_tags: \n",
      "\n",
      "words: Anna älskar Kurt\n",
      "i: 1 (current word: älskar)\n",
      "pred_tags: PM\n",
      "\n",
      "words: Anna älskar Kurt\n",
      "i: 2 (current word: Kurt)\n",
      "pred_tags: PM VB\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Anna', 'PM'), ('älskar', 'VB'), ('Kurt', 'PM')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_tagger.tag(\"Anna älskar Kurt\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that a feature vector is represented as a list of features. With this vector, the tagger then predicts the next tag using the classification rule for the perceptron, and updates the configuration before moving on to the next word. Finally, `tag()` returns the tagged sentence.\n",
    "\n",
    "### Training\n",
    "\n",
    "Training is based on the learning algorithm for the averaged perceptron. Note that the weight vectors need to be updated for each word, not for each sentence. The tagger maintains a list of already predicted tags as part of its configuration. The tagger trains for a single epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced: Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the advanced part of this lab, you will practice your skills in **feature engineering**, the task of identifying useful features for a machine learning system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"panel panel-primary\">\n",
    "<div class=\"panel-heading\">Problem 2</div>\n",
    "<div class=\"panel-body\">\n",
    "Think about which features could be useful for tagging and re-implement the method `get_features()` in the class `OurTagger` accordingly. Experiment not only with atomic features but also with different feature combinations (pairs or tuples of features). The goal is to create a system whose accuracy on the test data is as high as possible. Provide a short description of how you came up with your features.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first idea was to create a feature window that covers the words infront and behind our word of intreset. For the word infront we also included the predicted tag as a feature. To improve the the accuracy we thought that giving the word of interest more weight would help. We beleive that this feature is the most important one to predict the tag of it. To increase the weight of it we simply added more features of the word in focus. We testet some numbers of the same feature and kept the best one. To improve the accuracy further we tried to create tuples as features. Because we belive that the word in intrest is the most imporant we chose to combine this feature with the other features. We tried a couple of different combination and our final and best implementation achieves around 93% accuracy.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
